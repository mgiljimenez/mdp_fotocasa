fviz_eig(res.pca, addlabels = TRUE) +
geom_hline(yintercept=VPmedio, linetype=2, color="red")
kable(eig.val[1:7,])
#install.packages("caret")  # Si no lo tienes instalado
#install.packages("pls")    # Para PCA + Regresión
library(caret)
library(pls)
set.seed(123)  # Fijamos semilla para reproducibilidad
# Definir variables predictoras y variable objetivo
X <- variables[, !(names(variables) %in% c("priceAmount"))]  # Excluir "Precio"
Y <- variables$priceAmount  # Variable objetivo
# Configuración de validación cruzada (10-fold cross-validation)
control <- trainControl(method = "cv", number = 10)
# Entrenar modelo de regresión con PCA
modelo_pcr <- train(
priceAmount ~ .,      # Fórmula: Predecir Precio con todas las variables
data = variables,
method = "pcr",  # "pcr" = Regresión con PCA
trControl = control,
tuneLength = 10  # Probar hasta 10 componentes principales
)
# Mostrar resumen del modelo
print(modelo_pcr)
# Graficar error vs. número de componentes principales
plot(modelo_pcr)
K=3
misScores = res.pca$ind$coord[,1:K]
miT2 = colSums(t(misScores**2)/eig.val[1:K,1])
I = nrow(variables)
F95 = K*(I**2 - 1)/(I*(I - K)) * qf(0.95, K, I-K)
F99 = K*(I**2 - 1)/(I*(I - K)) * qf(0.99, K, I-K)
plot(1:length(miT2), miT2, type = "p", xlab = "Pisos", ylab = "T2")
abline(h = F95, col = "orange", lty = 2, lwd = 2)
abline(h = F99, col = "red3", lty = 2, lwd = 2)
library(grid)
library(gridExtra)
p1 = fviz_pca_ind(res.pca, axes = c(1,2), geom = c("point"),
habillage = factor(miT2 > F95)) +
tune::coord_obs_pred()
p2 = fviz_pca_ind(res.pca, axes = c(1,3), geom = c("point"),
habillage = factor(miT2 > F95)) +
tune::coord_obs_pred()
grid.arrange(p1,p2, nrow = 1)
# 1. Obtener cargas y scores
loadings <- res.pca$svd$U
scores <- res.pca$ind$coord
# 2. Reconstrucción de los datos desde el espacio PCA
reconstruccion <- scores %*% t(loadings)
# 3. Calcular residuos
residuos <- res.pca$call$X - reconstruccion
# 4. Calcular el estadístico Q (suma de los residuos al cuadrado por fila)
Q_estadistico <- rowSums(residuos^2)
# 5. Calcular umbral de atípicos basado en la distribución de Q
umbral_Q <- quantile(Q_estadistico, 0.95)  # Percentil 95
# 6. Identificar observaciones no bien explicadas por el modelo
datos_no_ajustados <- variables[Q_estadistico > umbral_Q, ]
# 7. Agregar Q al dataframe para análisis adicional
variables$Q <- Q_estadistico
# 8. Contar y calcular porcentaje de datos no bien ajustados
num_no_ajustados <- nrow(datos_no_ajustados)
porcentaje_no_ajustados <- (num_no_ajustados / nrow(variables)) * 100
# 9. Imprimir resultados
print(paste("Número de observaciones no explicadas bien por el modelo:", num_no_ajustados))
print(paste("Porcentaje de observaciones no explicadas:", round(porcentaje_no_ajustados, 2), "%"))
print(paste("Umbral de Q para detectar datos no ajustados:", round(umbral_Q, 4)))
# 10. Graficar Q con umbral
library(ggplot2)
ggplot(variables, aes(x = 1:nrow(variables), y = Q)) +
geom_point(aes(color = ifelse(Q > umbral_Q, "No ajustado", "Bien ajustado"))) +
scale_color_manual(values = c("Bien ajustado" = "blue", "No ajustado" = "red")) +
labs(title = "Observaciones no explicadas bien por el modelo (Q)",
x = "Índice de observaciones", y = "Estadístico Q", color = "Categoría") +
theme_minimal()
anomalas = which(miT2 > F95)
anomalas
pisos_sin_anomalos=variables[-anomalas,]
library(knitr)
library(FactoMineR)
library(factoextra)
res.pca = PCA(pisos_sin_anomalos, scale.unit = TRUE, graph = FALSE, ncp = 10,
quanti.sup = 13:15)
eig.val <- get_eigenvalue(res.pca)
VPmedio = 100 * (1/nrow(eig.val))
fviz_eig(res.pca, addlabels = TRUE) +
geom_hline(yintercept=VPmedio, linetype=2, color="red")
kable(eig.val[1:7,])
fviz_pca_var(res.pca, axes = c(1,2), repel = TRUE, col.var = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
fviz_pca_var(res.pca, axes = c(1,3), repel = TRUE, col.var = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
#no hacemos grafico de scores porque resulta ilegible, ¿por barrios/vecindarios? MIRAR MAÑANA
fviz_contrib(res.pca, choice = "var", axes = 1)
fviz_contrib(res.pca, choice = "var", axes = 2)
fviz_contrib(res.pca, choice = "var", axes = 3)
# 1. Obtener cargas y scores
loadings <- res.pca$svd$U
scores <- res.pca$ind$coord
# 2. Reconstrucción de los datos desde el espacio PCA
reconstruccion <- scores %*% t(loadings)
# 3. Calcular residuos
residuos <- res.pca$call$X - reconstruccion
# 4. Calcular el estadístico Q (suma de los residuos al cuadrado por fila)
Q_estadistico <- rowSums(residuos^2)
# 5. Calcular umbral de atípicos basado en la distribución de Q
umbral_Q <- quantile(Q_estadistico, 0.95)  # Percentil 95
# 6. Identificar observaciones no bien explicadas por el modelo
datos_no_ajustados <- variables[Q_estadistico > umbral_Q, ]
length(Q_estadistico)  # Número de observaciones en Q_estadistico
nrow(variables)        # Número de filas en variables
length(Q_estadistico)  # Número de observaciones en Q_estadistico
# 1. Asegurarse de que el PCA se haga sobre todas las observaciones de 'variables'
res.pca <- PCA(variables, scale.unit = TRUE, graph = FALSE, ncp = 10)
# 2. Obtener las coordenadas (scores) de las observaciones del PCA
scores <- res.pca$ind$coord  # Estas son las coordenadas de las observaciones en el espacio PCA
# 3. Reconstruir las observaciones desde el espacio PCA
loadings <- res.pca$svd$U  # Cargas del PCA
reconstruccion <- scores %*% t(loadings)  # Reconstrucción de los datos
# 4. Calcular los residuos
residuos <- variables - reconstruccion  # Diferencia entre los datos originales y la reconstrucción
# 5. Calcular el estadístico Q (suma de los residuos al cuadrado por fila)
Q_estadistico <- rowSums(residuos^2)
# 6. Calcular el umbral de atípicos basado en el percentil 95 de Q
umbral_Q <- quantile(Q_estadistico, 0.95)  # Percentil 95
# 7. Asegurarse de que las dimensiones coincidan: agregar Q_estadistico al dataframe 'variables'
variables$Q <- Q_estadistico  # Añadir el estadístico Q al dataframe
# 8. Identificar observaciones no bien ajustadas por el modelo
datos_no_ajustados <- subset(variables, Q > umbral_Q)
# 9. Contar y calcular porcentaje de datos no bien ajustados
num_no_ajustados <- nrow(datos_no_ajustados)
porcentaje_no_ajustados <- (num_no_ajustados / nrow(variables)) * 100
# 10. Imprimir resultados
print(paste("Número de observaciones no explicadas bien por el modelo:", num_no_ajustados))
print(paste("Porcentaje de observaciones no explicadas:", round(porcentaje_no_ajustados, 2), "%"))
print(paste("Umbral de Q para detectar datos no ajustados:", round(umbral_Q, 4)))
# 11. Graficar Q con umbral
library(ggplot2)
ggplot(variables, aes(x = 1:nrow(variables), y = Q)) +
geom_point(aes(color = ifelse(Q > umbral_Q, "No ajustado", "Bien ajustado"))) +
scale_color_manual(values = c("Bien ajustado" = "blue", "No ajustado" = "red")) +
labs(title = "Observaciones no explicadas bien por el modelo (Q)",
x = "Índice de observaciones", y = "Estadístico Q", color = "Categoría") +
theme_minimal()
library(readxl)
fotocasa = read_excel("fotocasaImp.xlsx")
variables <- fotocasa[, c(9,10,11,14,15,16,17,18,19,21,23,25,26,27,28,29,30,31, 32)]
print(summary(variables))
library(knitr)
library(FactoMineR)
library(factoextra)
res.pca = PCA(variables, scale.unit = TRUE, graph = FALSE, ncp = 10,
quanti.sup = 13:15)
eig.val <- get_eigenvalue(res.pca)
VPmedio = 100 * (1/nrow(eig.val))
fviz_eig(res.pca, addlabels = TRUE) +
geom_hline(yintercept=VPmedio, linetype=2, color="red")
kable(eig.val[1:7,])
#install.packages("caret")  # Si no lo tienes instalado
#install.packages("pls")    # Para PCA + Regresión
library(caret)
library(pls)
set.seed(123)  # Fijamos semilla para reproducibilidad
# Definir variables predictoras y variable objetivo
X <- variables[, !(names(variables) %in% c("priceAmount"))]  # Excluir "Precio"
Y <- variables$priceAmount  # Variable objetivo
# Configuración de validación cruzada (10-fold cross-validation)
control <- trainControl(method = "cv", number = 10)
# Entrenar modelo de regresión con PCA
modelo_pcr <- train(
priceAmount ~ .,      # Fórmula: Predecir Precio con todas las variables
data = variables,
method = "pcr",  # "pcr" = Regresión con PCA
trControl = control,
tuneLength = 10  # Probar hasta 10 componentes principales
)
# Mostrar resumen del modelo
print(modelo_pcr)
# Graficar error vs. número de componentes principales
plot(modelo_pcr)
K=3
misScores = res.pca$ind$coord[,1:K]
miT2 = colSums(t(misScores**2)/eig.val[1:K,1])
I = nrow(variables)
F95 = K*(I**2 - 1)/(I*(I - K)) * qf(0.95, K, I-K)
F99 = K*(I**2 - 1)/(I*(I - K)) * qf(0.99, K, I-K)
plot(1:length(miT2), miT2, type = "p", xlab = "Pisos", ylab = "T2")
abline(h = F95, col = "orange", lty = 2, lwd = 2)
abline(h = F99, col = "red3", lty = 2, lwd = 2)
library(grid)
library(gridExtra)
p1 = fviz_pca_ind(res.pca, axes = c(1,2), geom = c("point"),
habillage = factor(miT2 > F95)) +
tune::coord_obs_pred()
p2 = fviz_pca_ind(res.pca, axes = c(1,3), geom = c("point"),
habillage = factor(miT2 > F95)) +
tune::coord_obs_pred()
grid.arrange(p1,p2, nrow = 1)
# 1. Asegurarse de que el PCA se haga sobre todas las observaciones de 'variables'
res.pca <- PCA(variables, scale.unit = TRUE, graph = FALSE, ncp = 10)
# 2. Obtener las coordenadas (scores) de las observaciones del PCA
scores <- res.pca$ind$coord  # Estas son las coordenadas de las observaciones en el espacio PCA
# 3. Reconstruir las observaciones desde el espacio PCA
loadings <- res.pca$svd$U  # Cargas del PCA
reconstruccion <- scores %*% t(loadings)  # Reconstrucción de los datos
# 4. Calcular los residuos
residuos <- variables - reconstruccion  # Diferencia entre los datos originales y la reconstrucción
# 5. Calcular el estadístico Q (suma de los residuos al cuadrado por fila)
Q_estadistico <- rowSums(residuos^2)
# 6. Calcular el umbral de atípicos basado en el percentil 95 de Q
umbral_Q <- quantile(Q_estadistico, 0.95)  # Percentil 95
# 7. Asegurarse de que las dimensiones coincidan: agregar Q_estadistico al dataframe 'variables'
variables$Q <- Q_estadistico  # Añadir el estadístico Q al dataframe
# 8. Identificar observaciones no bien ajustadas por el modelo
datos_no_ajustados <- subset(variables, Q > umbral_Q)
# 9. Contar y calcular porcentaje de datos no bien ajustados
num_no_ajustados <- nrow(datos_no_ajustados)
porcentaje_no_ajustados <- (num_no_ajustados / nrow(variables)) * 100
# 10. Imprimir resultados
print(paste("Número de observaciones no explicadas bien por el modelo:", num_no_ajustados))
print(paste("Porcentaje de observaciones no explicadas:", round(porcentaje_no_ajustados, 2), "%"))
print(paste("Umbral de Q para detectar datos no ajustados:", round(umbral_Q, 4)))
# 11. Graficar Q con umbral
library(ggplot2)
ggplot(variables, aes(x = 1:nrow(variables), y = Q)) +
geom_point(aes(color = ifelse(Q > umbral_Q, "No ajustado", "Bien ajustado"))) +
scale_color_manual(values = c("Bien ajustado" = "blue", "No ajustado" = "red")) +
labs(title = "Observaciones no explicadas bien por el modelo (Q)",
x = "Índice de observaciones", y = "Estadístico Q", color = "Categoría") +
theme_minimal()
anomalas = which(miT2 > F95)
anomalas
pisos_sin_anomalos=variables[-anomalas,]
library(knitr)
library(FactoMineR)
library(factoextra)
res.pca = PCA(pisos_sin_anomalos, scale.unit = TRUE, graph = FALSE, ncp = 10,
quanti.sup = 13:15)
eig.val <- get_eigenvalue(res.pca)
VPmedio = 100 * (1/nrow(eig.val))
fviz_eig(res.pca, addlabels = TRUE) +
geom_hline(yintercept=VPmedio, linetype=2, color="red")
kable(eig.val[1:7,])
fviz_pca_var(res.pca, axes = c(1,2), repel = TRUE, col.var = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
fviz_pca_var(res.pca, axes = c(1,3), repel = TRUE, col.var = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
#no hacemos grafico de scores porque resulta ilegible, ¿por barrios/vecindarios? MIRAR MAÑANA
fviz_contrib(res.pca, choice = "var", axes = 1)
fviz_contrib(res.pca, choice = "var", axes = 2)
fviz_contrib(res.pca, choice = "var", axes = 3)
# 1. Realizar PCA sobre el dataframe variables
res.pca <- PCA(variables, scale.unit = TRUE, graph = FALSE, ncp = 10)
# 2. Obtener las coordenadas (scores) de las observaciones
scores <- res.pca$ind$coord  # Estas son las coordenadas de las observaciones en el espacio PCA
# 3. Reconstrucción de las observaciones desde el espacio PCA
loadings <- res.pca$svd$U  # Cargas del PCA
reconstruccion <- scores %*% t(loadings)  # Reconstrucción de los datos
# 4. Calcular los residuos (diferencia entre los datos originales y la reconstrucción)
residuos <- variables - reconstruccion  # Diferencia entre los datos originales y la reconstrucción
# 5. Calcular el estadístico Q (suma de los residuos al cuadrado por fila)
Q_estadistico <- rowSums(residuos^2)
# 6. Calcular el umbral de atípicos basado en el percentil 95 de Q
umbral_Q <- quantile(Q_estadistico, 0.95)  # Percentil 95
# 7. Identificar las observaciones que no están bien ajustadas
datos_no_ajustados <- variables[Q_estadistico > umbral_Q, ]
# 8. Contar el número de observaciones no ajustadas
num_no_ajustados <- nrow(datos_no_ajustados)
# 9. Calcular el porcentaje de observaciones no ajustadas
porcentaje_no_ajustados <- (num_no_ajustados / nrow(variables)) * 100
# 10. Imprimir los resultados
print(paste("Número de observaciones no explicadas bien por el modelo:", num_no_ajustados))
print(paste("Porcentaje de observaciones no explicadas:", round(porcentaje_no_ajustados, 2), "%"))
print(paste("Umbral de Q para detectar datos no ajustados:", round(umbral_Q, 4)))
# 11. Graficar el estadístico Q y las observaciones no ajustadas
library(ggplot2)
ggplot(data.frame(ID = 1:nrow(variables), Q = Q_estadistico), aes(x = ID, y = Q)) +
geom_point(aes(color = ifelse(Q > umbral_Q, "No ajustado", "Bien ajustado"))) +
scale_color_manual(values = c("Bien ajustado" = "blue", "No ajustado" = "red")) +
labs(title = "Observaciones no explicadas bien por el modelo (Q)",
x = "Índice de observaciones", y = "Estadístico Q", color = "Categoría") +
theme_minimal()
library(readxl)
fotocasa = read_excel("fotocasaImp.xlsx")
variables <- fotocasa[, c(9,10,11,14,15,16,17,18,19,21,23,25,26,27,28,29,30,31, 32)]
print(summary(variables))
library(knitr)
library(FactoMineR)
library(factoextra)
res.pca = PCA(variables, scale.unit = TRUE, graph = FALSE, ncp = 10,
quanti.sup = 13:15)
eig.val <- get_eigenvalue(res.pca)
VPmedio = 100 * (1/nrow(eig.val))
fviz_eig(res.pca, addlabels = TRUE) +
geom_hline(yintercept=VPmedio, linetype=2, color="red")
kable(eig.val[1:7,])
#install.packages("caret")  # Si no lo tienes instalado
#install.packages("pls")    # Para PCA + Regresión
library(caret)
library(pls)
set.seed(123)  # Fijamos semilla para reproducibilidad
# Definir variables predictoras y variable objetivo
X <- variables[, !(names(variables) %in% c("priceAmount"))]  # Excluir "Precio"
Y <- variables$priceAmount  # Variable objetivo
# Configuración de validación cruzada (10-fold cross-validation)
control <- trainControl(method = "cv", number = 10)
# Entrenar modelo de regresión con PCA
modelo_pcr <- train(
priceAmount ~ .,      # Fórmula: Predecir Precio con todas las variables
data = variables,
method = "pcr",  # "pcr" = Regresión con PCA
trControl = control,
tuneLength = 10  # Probar hasta 10 componentes principales
)
# Mostrar resumen del modelo
print(modelo_pcr)
# Graficar error vs. número de componentes principales
plot(modelo_pcr)
K=3
misScores = res.pca$ind$coord[,1:K]
miT2 = colSums(t(misScores**2)/eig.val[1:K,1])
I = nrow(variables)
F95 = K*(I**2 - 1)/(I*(I - K)) * qf(0.95, K, I-K)
F99 = K*(I**2 - 1)/(I*(I - K)) * qf(0.99, K, I-K)
plot(1:length(miT2), miT2, type = "p", xlab = "Pisos", ylab = "T2")
abline(h = F95, col = "orange", lty = 2, lwd = 2)
abline(h = F99, col = "red3", lty = 2, lwd = 2)
library(grid)
library(gridExtra)
p1 = fviz_pca_ind(res.pca, axes = c(1,2), geom = c("point"),
habillage = factor(miT2 > F95)) +
tune::coord_obs_pred()
p2 = fviz_pca_ind(res.pca, axes = c(1,3), geom = c("point"),
habillage = factor(miT2 > F95)) +
tune::coord_obs_pred()
grid.arrange(p1,p2, nrow = 1)
# 1. Realizar PCA sobre el dataframe variables
# 2. Obtener las coordenadas (scores) de las observaciones
scores <- res.pca$ind$coord  # Estas son las coordenadas de las observaciones en el espacio PCA
# 3. Reconstrucción de las observaciones desde el espacio PCA
loadings <- res.pca$svd$U  # Cargas del PCA
reconstruccion <- scores %*% t(loadings)  # Reconstrucción de los datos
# 4. Calcular los residuos (diferencia entre los datos originales y la reconstrucción)
residuos <- variables - reconstruccion  # Diferencia entre los datos originales y la reconstrucción
# 5. Calcular el estadístico Q (suma de los residuos al cuadrado por fila)
Q_estadistico <- rowSums(residuos^2)
# 6. Calcular el umbral de atípicos basado en el percentil 95 de Q
umbral_Q <- quantile(Q_estadistico, 0.95)  # Percentil 95
# 7. Identificar las observaciones que no están bien ajustadas
datos_no_ajustados <- variables[Q_estadistico > umbral_Q, ]
# 8. Contar el número de observaciones no ajustadas
num_no_ajustados <- nrow(datos_no_ajustados)
# 9. Calcular el porcentaje de observaciones no ajustadas
porcentaje_no_ajustados <- (num_no_ajustados / nrow(variables)) * 100
# 10. Imprimir los resultados
print(paste("Número de observaciones no explicadas bien por el modelo:", num_no_ajustados))
print(paste("Porcentaje de observaciones no explicadas:", round(porcentaje_no_ajustados, 2), "%"))
print(paste("Umbral de Q para detectar datos no ajustados:", round(umbral_Q, 4)))
# 11. Graficar el estadístico Q y las observaciones no ajustadas
library(ggplot2)
ggplot(data.frame(ID = 1:nrow(variables), Q = Q_estadistico), aes(x = ID, y = Q)) +
geom_point(aes(color = ifelse(Q > umbral_Q, "No ajustado", "Bien ajustado"))) +
scale_color_manual(values = c("Bien ajustado" = "blue", "No ajustado" = "red")) +
labs(title = "Observaciones no explicadas bien por el modelo (Q)",
x = "Índice de observaciones", y = "Estadístico Q", color = "Categoría") +
theme_minimal()
anomalas = which(miT2 > F95)
anomalas
pisos_sin_anomalos=variables[-anomalas,]
library(knitr)
library(FactoMineR)
library(factoextra)
res.pca = PCA(pisos_sin_anomalos, scale.unit = TRUE, graph = FALSE, ncp = 10,
quanti.sup = 13:15)
eig.val <- get_eigenvalue(res.pca)
VPmedio = 100 * (1/nrow(eig.val))
fviz_eig(res.pca, addlabels = TRUE) +
geom_hline(yintercept=VPmedio, linetype=2, color="red")
kable(eig.val[1:7,])
library(readxl)
fotocasa = read_excel("fotocasaImp.xlsx")
variables <- fotocasa[, c(9,10,11,14,15,16,17,18,19,21,23,25,26,27,28,29,30,31, 32)]
print(summary(variables))
library(knitr)
library(FactoMineR)
library(factoextra)
res.pca = PCA(variables, scale.unit = TRUE, graph = FALSE, ncp = 10,
quanti.sup = 13:15)
eig.val <- get_eigenvalue(res.pca)
VPmedio = 100 * (1/nrow(eig.val))
fviz_eig(res.pca, addlabels = TRUE) +
geom_hline(yintercept=VPmedio, linetype=2, color="red")
kable(eig.val[1:7,])
#install.packages("caret")  # Si no lo tienes instalado
#install.packages("pls")    # Para PCA + Regresión
library(caret)
library(pls)
set.seed(123)  # Fijamos semilla para reproducibilidad
# Definir variables predictoras y variable objetivo
X <- variables[, !(names(variables) %in% c("priceAmount"))]  # Excluir "Precio"
Y <- variables$priceAmount  # Variable objetivo
# Configuración de validación cruzada (10-fold cross-validation)
control <- trainControl(method = "cv", number = 10)
# Entrenar modelo de regresión con PCA
modelo_pcr <- train(
priceAmount ~ .,      # Fórmula: Predecir Precio con todas las variables
data = variables,
method = "pcr",  # "pcr" = Regresión con PCA
trControl = control,
tuneLength = 10  # Probar hasta 10 componentes principales
)
# Mostrar resumen del modelo
print(modelo_pcr)
# Graficar error vs. número de componentes principales
plot(modelo_pcr)
#install.packages("caret")  # Si no lo tienes instalado
#install.packages("pls")    # Para PCA + Regresión
library(caret)
library(pls)
set.seed(123)  # Fijamos semilla para reproducibilidad
# Definir variables predictoras y variable objetivo
X <- variables[, !(names(variables) %in% c("priceAmount"))]  # Excluir "Precio"
Y <- variables$priceAmount  # Variable objetivo
# Configuración de validación cruzada (10-fold cross-validation)
control <- trainControl(method = "cv", number = 10)
# Entrenar modelo de regresión con PCA
modelo_pcr <- train(
priceAmount ~ .,      # Fórmula: Predecir Precio con todas las variables
data = variables,
method = "pcr",  # "pcr" = Regresión con PCA
trControl = control,
tuneLength = 10  # Probar hasta 10 componentes principales
)
# Mostrar resumen del modelo
print(modelo_pcr)
# Graficar error vs. número de componentes principales
plot(modelo_pcr)
K=3
misScores = res.pca$ind$coord[,1:K]
miT2 = colSums(t(misScores**2)/eig.val[1:K,1])
I = nrow(variables)
F95 = K*(I**2 - 1)/(I*(I - K)) * qf(0.95, K, I-K)
F99 = K*(I**2 - 1)/(I*(I - K)) * qf(0.99, K, I-K)
plot(1:length(miT2), miT2, type = "p", xlab = "Pisos", ylab = "T2")
abline(h = F95, col = "orange", lty = 2, lwd = 2)
abline(h = F99, col = "red3", lty = 2, lwd = 2)
library(grid)
library(gridExtra)
p1 = fviz_pca_ind(res.pca, axes = c(1,2), geom = c("point"),
habillage = factor(miT2 > F95)) +
tune::coord_obs_pred()
p2 = fviz_pca_ind(res.pca, axes = c(1,3), geom = c("point"),
habillage = factor(miT2 > F95)) +
tune::coord_obs_pred()
grid.arrange(p1,p2, nrow = 1)
# 2. Obtener las coordenadas (scores) de las observaciones
scores <- res.pca$ind$coord  # Estas son las coordenadas de las observaciones en el espacio PCA
# 3. Reconstrucción de las observaciones desde el espacio PCA
loadings <- res.pca$svd$U  # Cargas del PCA
reconstruccion <- scores %*% t(loadings)  # Reconstrucción de los datos
# 4. Calcular los residuos (diferencia entre los datos originales y la reconstrucción)
residuos <- variables - reconstruccion  # Diferencia entre los datos originales y la reconstrucción
# 5. Calcular el estadístico Q (suma de los residuos al cuadrado por fila)
Q_estadistico <- rowSums(residuos^2)
# 6. Calcular el umbral de atípicos basado en el percentil 95 de Q
umbral_Q <- quantile(Q_estadistico, 0.95)  # Percentil 95
# 7. Identificar las observaciones que no están bien ajustadas
datos_no_ajustados <- variables[Q_estadistico > umbral_Q, ]
# 8. Contar el número de observaciones no ajustadas
num_no_ajustados <- nrow(datos_no_ajustados)
# 9. Calcular el porcentaje de observaciones no ajustadas
porcentaje_no_ajustados <- (num_no_ajustados / nrow(variables)) * 100
# 10. Imprimir los resultados
print(paste("Número de observaciones no explicadas bien por el modelo:", num_no_ajustados))
print(paste("Porcentaje de observaciones no explicadas:", round(porcentaje_no_ajustados, 2), "%"))
print(paste("Umbral de Q para detectar datos no ajustados:", round(umbral_Q, 4)))
# 11. Graficar el estadístico Q y las observaciones no ajustadas
library(ggplot2)
ggplot(data.frame(ID = 1:nrow(variables), Q = Q_estadistico), aes(x = ID, y = Q)) +
geom_point(aes(color = ifelse(Q > umbral_Q, "No ajustado", "Bien ajustado"))) +
scale_color_manual(values = c("Bien ajustado" = "blue", "No ajustado" = "red")) +
labs(title = "Observaciones no explicadas bien por el modelo (Q)",
x = "Índice de observaciones", y = "Estadístico Q", color = "Categoría") +
theme_minimal()
anomalas = which(miT2 > F95)
anomalas
pisos_sin_anomalos=variables[-anomalas,]
library(knitr)
library(FactoMineR)
library(factoextra)
res.pca_sin_anomalos = PCA(pisos_sin_anomalos, scale.unit = TRUE, graph = FALSE, ncp = 10,
quanti.sup = 13:15)
eig.val <- get_eigenvalue(res.pca_sin_anomalos)
VPmedio = 100 * (1/nrow(eig.val))
fviz_eig(res.pca_sin_anomalos, addlabels = TRUE) +
geom_hline(yintercept=VPmedio, linetype=2, color="red")
kable(eig.val[1:7,])
fviz_pca_var(res.pca, axes = c(1,2), repel = TRUE, col.var = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
fviz_pca_var(res.pca, axes = c(1,3), repel = TRUE, col.var = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
#no hacemos grafico de scores porque resulta ilegible, ¿por barrios/vecindarios? MIRAR MAÑANA
fviz_pca_var(res.pca, axes = c(1,2), repel = TRUE, col.var = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
fviz_pca_var(res.pca, axes = c(1,3), repel = TRUE, col.var = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
#no hacemos grafico de scores porque resulta ilegible, ¿por barrios/vecindarios? MIRAR MAÑANA
fviz_contrib(res.pca, choice = "var", axes = 1)
fviz_contrib(res.pca, choice = "var", axes = 2)
fviz_contrib(res.pca, choice = "var", axes = 3)
fviz_pca_ind(res.pca, axes = c(1,2), repel = TRUE, col.var = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
fviz_pca_var(res.pca, axes = c(1,2), repel = TRUE, col.var = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
