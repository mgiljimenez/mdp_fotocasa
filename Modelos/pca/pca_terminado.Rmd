---
title: "pca"
author: "Ana"
date: '`r Sys.Date()`'
output: html_document
---

```{r setup, include=FALSE}
library(readxl)
fotocasa = read_excel("fotocasaImp.xlsx")
fotocasa <- as.data.frame(fotocasa)

rownames(fotocasa) <- fotocasa[[1]]
fotocasa
variables <- fotocasa[, c(9,10,11,13,14,15,16,17,18,19,21,22,23,24,25,26,27,28,29,30,31, 32, 33)]
```

```{r pca}
library(knitr)
library(FactoMineR)
library(factoextra)
res.pca = PCA(variables, scale.unit = TRUE, graph = FALSE, ncp = 10, quanti.sup=23)
eig.val <- get_eigenvalue(res.pca)
VPmedio = 100 * (1/nrow(eig.val))
fviz_eig(res.pca, addlabels = TRUE) +
  geom_hline(yintercept=VPmedio, linetype=2, color="red")
kable(eig.val[1:7,])
```
```{r validacion_cruzada}
#install.packages("caret")  # Si no lo tienes instalado
#install.packages("pls")    # Para PCA + Regresión
library(caret)
library(pls)
set.seed(123)  # Fijamos semilla para reproducibilidad

# Definir variables predictoras y variable objetivo
X <- variables[, !(names(variables) %in% c("priceAmount", "priceAmountDrop"))]  # Excluir "Precio"
Y <- variables$priceAmount  # Variable objetivo

# Configuración de validación cruzada (10-fold cross-validation)
control <- trainControl(method = "cv", number = 10)

# Entrenar modelo de regresión con PCA
modelo_pcr <- train(
  priceAmount ~ .,      # Fórmula: Predecir Precio con todas las variables
  data = variables[,c(1:22)],
  method = "pcr",  # "pcr" = Regresión con PCA
  trControl = control,
  tuneLength = 10  # Probar hasta 10 componentes principales
)

# Mostrar resumen del modelo
print(modelo_pcr)

# Graficar error vs. número de componentes principales
plot(modelo_pcr)
```
Seguidamente, estudiaremos los diferentes criterios para seleccionar el número de componentes vistos en clase.
En primer lugar, para explicar el 80% de los datos necesitaríamos incluir 7 componentes; aunque esta opción
complicaría excesivamente la interpretación de resultados. Paralelamente, aplicando el criterio del codo
seleccionaríamos entre 3 y 4 componentes.
Para decidir el número definitivo, aplicaremos un modelo predictivo de validación cruzada.
El proceso es el siguiente:
1. Eliminar un grupo de observaciones
2. Ajustar el modelo con las observaciones restantes
3. Predecir las observaciones eliminadas
4. Repetir hasta haber predicho todas las observaciones
La medida del error de dicha predicción es la suma de cuadrados de los errores
de predicción.
```{r pca_3_componentes}
K=3
res.pca = PCA(variables, scale.unit = TRUE, graph = FALSE, ncp = K, quanti.sup=23)
eig.val <- get_eigenvalue(res.pca)
VPmedio = 100 * (1/nrow(eig.val))
fviz_eig(res.pca, addlabels = TRUE) +
  geom_hline(yintercept=VPmedio, linetype=2, color="red")
kable(eig.val[1:K,])
```


De acuerdo con los resultados obtenidos, el error de las predicciones se estabiliza en 3 componentes principales,
con un valor de aproximadamente 470€ (un 30% del precio medio). Asimismo, la bondad del ajuste también converge
en 3 dimensiones, con un valor ligeramente superior a 0,5. A partir de estos estos valores, aunque nuestro modelo
de tres componentes es mejorable, podemos considerar aceptables sus predicciones.

```{r distancias_dentro_modelo}

misScores = res.pca$ind$coord[,1:K]
miT2 = colSums(t(misScores**2)/eig.val[1:K,1])
I = nrow(variables)
F95 = K*(I**2 - 1)/(I*(I - K)) * qf(0.95, K, I-K)
F99 = K*(I**2 - 1)/(I*(I - K)) * qf(0.99, K, I-K)

plot(1:length(miT2), miT2, type = "p", xlab = "Pisos", ylab = "T2")
abline(h = F95, col = "orange", lty = 2, lwd = 2)
abline(h = F99, col = "red3", lty = 2, lwd = 2)
library(grid)
library(gridExtra)


p1 = fviz_pca_ind(res.pca, axes = c(1,2), geom = c("point"),
                  habillage = factor(miT2 > F95)) +
  tune::coord_obs_pred()

p2 = fviz_pca_ind(res.pca, axes = c(1,3), geom = c("point"), 
                  habillage = factor(miT2 > F95)) +
  tune::coord_obs_pred() 


grid.arrange(p1,p2, nrow = 1)
```
```{r funcionT2}
contribT2 = function (X, scores, loadings, eigenval, observ, cutoff = 2) {
  # X is data matrix and must be centered (or centered and scaled if data were scaled)
  misScoresNorm = t(t(scores**2) / eigenval)
  misContrib = NULL
  for (oo in observ) {
    print(rownames(scores)[oo])
    print(scores[oo,])
    misPCs = which(as.numeric(misScoresNorm[oo,]) > cutoff)
    lacontri = sapply(misPCs, function (cc) (scores[oo,cc]/eigenval[cc])*loadings[,cc]*X[oo,])
    lacontri = rowSums((1*(sign(lacontri) == 1))*lacontri)
    misContrib = cbind(misContrib, lacontri)
  }
  colnames(misContrib) = rownames(misScoresNorm[observ,])
  return(misContrib)
}
```


```{r calculosT2}
# Recuperamos los datos utilizados en el modelo PCA, centrados y escalados
variablesCE = variables[,setdiff(colnames(variables), c("priceAmountDrop"))]
variablesCE = scale(variablesCE, center = TRUE, scale = TRUE)
X = as.matrix(variablesCE)

# Calculamos los loadings a partir de las coordenadas de las variables
# ya que la librería FactoMineR nos devuelve los loadings ponderados 
# por la importancia de cada componente principal.
misLoadings = sweep(res.pca$var$coord, 2, sqrt(res.pca$eig[1:K,1]), FUN="/")
# Calculamos las contribuciones
mycontrisT2 = contribT2(X = X, scores = misScores, loadings = misLoadings, 
                        eigenval = eig.val[1:K,1], observ = which.max(miT2),
                        cutoff = 2)
```

El piso seleccionado como atípico extremo es un ático de lujo en el centro de Valencia, por lo que es normal que su precio sea considerado excesivamente elevado por el modelo.
```{r precio_outlierExtremo}
par(mar = c(10,2.3,3,1))
barplot(mycontrisT2[,1],las=2, #cex.names = 0.5,
        main= paste0("Observación: ", rownames(variables)[which.max(miT2)]))
# Suponiendo que tienes tus scores, loadings y la cantidad de componentes que deseas usar (3 en este caso)
predicted_price = sum(scores[which.max(miT2), 1:3] * misLoadings[1:3, 1:3])
centros <- attributes(variablesCE)$`scaled:center`
escalas <- attributes(variablesCE)$`scaled:scale`
predicted_price <- predicted_price * escalas["priceAmount"] + centros["priceAmount"]

# Mostrar el resultado
predicted_price
```


```{r comparacion_Modelo/real}

real_price = variables$priceAmount[which.max(miT2)]  # Aquí usas el índice correspondiente
comparison = data.frame(Real_Price = real_price, Predicted_Price = predicted_price)
print(comparison)
```


```{r}
myE = X - misScores %*% t(misLoadings) 
mySCR = rowSums(myE^2)  
plot(1:length(mySCR), mySCR, type = "l", main = "Distancia al modelo", 
     ylab = "SCR", xlab = "Inmbuebles", ylim = c(0,180))
g = var(mySCR)/(2*mean(mySCR))
h = (2*mean(mySCR)^2)/var(mySCR)
chi2lim = g*qchisq(0.95, df = h)
chi2lim99 = g*qchisq(0.99, df = h)
abline(h = chi2lim, col = "orange", lty = 2, lwd = 2)
abline(h = chi2lim99, col = "red3", lty = 2, lwd = 2)
```

```{r}
# Umbral 99 %
atipicos_moderados=fotocasa$URL[ mySCR > chi2lim99 ]
atipicos_moderados
```

```{r}
## Función para calcular las contribuciones a la SCR
ContriSCR = function(E, SCR) {
  # E es la matriz de residuos del modelo 
  # SCR es la suma de cuadrados residual
  contribucion = NULL
  for (j in 1:length(SCR)){
    eind<-E[j,]
    signo<-sign(eind)
    contri<-(signo*(eind^2)/SCR[j])*100
    contribucion<-rbind(contribucion,contri)
  }
  rownames(contribucion) = rownames(E)
  return(contribucion)
}
## Calculamos las contribuciones de todas las observaciones
mycontris = ContriSCR(E = myE, SCR = mySCR)
## Gráfico para Special_K
barplot(mycontris["https://www.fotocasa.es/es/alquiler/vivienda/valencia-capital/amueblado-internet/185589991/d",],las=2, cex.names = 0.7,
        main=c('Contribuciones a SCR para un piso'))
```



```{r estadistico_Q}

# 2. Obtener las coordenadas (scores) de las observaciones
scores <- res.pca$ind$coord  # Estas son las coordenadas de las observaciones en el espacio PCA

# 3. Reconstrucción de las observaciones desde el espacio PCA
loadings <- res.pca$svd$U  # Cargas del PCA
reconstruccion <- scores %*% t(loadings)  # Reconstrucción de los datos

# 4. Calcular los residuos (diferencia entre los datos originales y la reconstrucción)
residuos <- variables - reconstruccion  # Diferencia entre los datos originales y la reconstrucción

# 5. Calcular el estadístico Q (suma de los residuos al cuadrado por fila)
Q_estadistico <- rowSums(residuos^2)

# 6. Calcular el umbral de atípicos basado en el percentil 95 de Q
umbral_Q <- quantile(Q_estadistico, 0.95)  # Percentil 95

# 7. Identificar las observaciones que no están bien ajustadas
datos_no_ajustados <- variables[Q_estadistico > umbral_Q, ]

# 8. Contar el número de observaciones no ajustadas
num_no_ajustados <- nrow(datos_no_ajustados)

# 9. Calcular el porcentaje de observaciones no ajustadas
porcentaje_no_ajustados <- (num_no_ajustados / nrow(variables)) * 100

# 10. Imprimir los resultados
print(paste("Número de observaciones no explicadas bien por el modelo:", num_no_ajustados))
print(paste("Porcentaje de observaciones no explicadas:", round(porcentaje_no_ajustados, 2), "%"))
print(paste("Umbral de Q para detectar datos no ajustados:", round(umbral_Q, 4)))

# 11. Graficar el estadístico Q y las observaciones no ajustadas
library(ggplot2)
ggplot(data.frame(ID = 1:nrow(variables), Q = Q_estadistico), aes(x = ID, y = Q)) +
  geom_point(aes(color = ifelse(Q > umbral_Q, "No ajustado", "Bien ajustado"))) +
  scale_color_manual(values = c("Bien ajustado" = "blue", "No ajustado" = "red")) +
  labs(title = "Observaciones no explicadas bien por el modelo (Q)",
       x = "Índice de observaciones", y = "Estadístico Q", color = "Categoría") +
  theme_minimal()

```




```{r filtrar_anomalos}
anomalas = which(miT2 > F95)
anomalas
pisos_sin_anomalos=variables[-anomalas,]
```

```{r sin_anomalos}
library(knitr)
library(FactoMineR)
library(factoextra)
res.pca_sin_anomalos = PCA(pisos_sin_anomalos, scale.unit = TRUE, graph = FALSE, ncp = K, quanti.sup=23)
eig.val <- get_eigenvalue(res.pca_sin_anomalos)
VPmedio = 100 * (1/nrow(eig.val))
fviz_eig(res.pca_sin_anomalos, addlabels = TRUE) +
  geom_hline(yintercept=VPmedio, linetype=2, color="red")
kable(eig.val[1:K,])
```
Al filtrar los pisos anómalos extremos y excluirlos del modelo, el resultado del PCA apenas varía. Por lo tanto, estos 
inmuebles no están generando componentes innecesarias ni influyendo en los resultados del análisis.
Teniendo esto en cuenta, continuaremos el análisis manteniendo los pisos atípicos en el modelo.



```{r loadings}

# Gráfico de las variables proyectadas en las primeras dos componentes
fviz_pca_var(res.pca, axes = c(1, 2), repel = TRUE, col.var = "contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))

# Gráfico de las variables proyectadas en las primeras y terceras componentes
fviz_pca_var(res.pca, axes = c(1, 3), repel = TRUE, col.var = "contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
#no hacemos grafico de scores porque resulta ilegible.
fviz_pca_var(res.pca, axes = c(2, 3), repel = TRUE, col.var = "contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))

```
```{r scores_barrio_plot}
# Cargar la librería dplyr si no está cargada
library(dplyr)

# Ver el resultado
head(fotocasa)

fotocasa$municipality <- as.factor(fotocasa$municipality)
library(RColorBrewer)

# Graficar los scores del PCA sin mostrar el número del individuo y coloreado por 'municipio'
fviz_pca_ind(res.pca, 
             axes = c(1, 2),  # Seleccionar los ejes 1 y 2
             repel = TRUE,    # Evitar el solapamiento de etiquetas
             label = "none",  # No mostrar el número del individuo
             habillage = fotocasa$municipality,  # Colorear por la variable 'minicipio'
             palette = rainbow(19),  # Usar paleta de colores
             #addEllipses = TRUE,  # Añadir elipses de concentración
             legend.title = "municipio"  # Título de la leyenda
)

# Graficar los scores del PCA sin mostrar el número del individuo y coloreado por 'municipio'
fviz_pca_ind(res.pca, 
             axes = c(1, 3),  # Seleccionar los ejes 1 y 2
             repel = TRUE,    # Evitar el solapamiento de etiquetas
             label = "none",  # No mostrar el número del individuo
             habillage = fotocasa$municipality,  # Colorear por la variable 'municipio'
             palette = rainbow(19),  # Usar paleta de colores
             #addEllipses = TRUE,  # Añadir elipses de concentración
             legend.title = "municipio"  # Título de la leyenda
)

```
```{r scores_tipo_piso_plot}
fotocasa$propertySubtypeId <- as.factor(fotocasa$propertySubtypeId)
library(RColorBrewer)

# Graficar los scores del PCA sin mostrar el número del individuo y coloreado por 'propertySubtypeId'
fviz_pca_ind(res.pca, 
             axes = c(1, 2),  # Seleccionar los ejes 1 y 2
             repel = TRUE,    # Evitar el solapamiento de etiquetas
             label = "none",  # No mostrar el número del individuo
             habillage = fotocasa$propertySubtypeId,  # Colorear por la variable 'propertySubtypeId'
             palette = rainbow(4),  # Usar paleta de colores
             #addEllipses = TRUE,  # Añadir elipses de concentración
             legend.title = "Property Subtype ID"  # Título de la leyenda
)

# Graficar los scores del PCA sin mostrar el número del individuo y coloreado por 'propertySubtypeId'
fviz_pca_ind(res.pca, 
             axes = c(1, 3),  # Seleccionar los ejes 1 y 2
             repel = TRUE,    # Evitar el solapamiento de etiquetas
             label = "none",  # No mostrar el número del individuo
             habillage = fotocasa$propertySubtypeId,  # Colorear por la variable 'propertySubtypeId'
             palette = rainbow(4),  # Usar paleta de colores
             #addEllipses = TRUE,  # Añadir elipses de concentración
             legend.title = "Property Subtype ID"  # Título de la leyenda
)

```


```{r contribucion_variables_primitivas}
fviz_contrib(res.pca, choice = "var", axes = 1)
fviz_contrib(res.pca, choice = "var", axes = 2)
fviz_contrib(res.pca, choice = "var", axes = 3)

```
```{r biplot}
fviz_pca_biplot(res.pca, axes = c(1, 2), repel = TRUE, 
                col.ind = fotocasa$municipality,  # Usar la columna 'municipio' para colorear los individuos
                col.var = "black",           # Las variables se mantienen en rojo
                label = "var") +           # Etiquetas de las variables activas
  labs(title = "Biplot del PCA: Separación por municipio")

fviz_pca_biplot(res.pca, axes = c(1, 3), repel = TRUE, 
                col.ind = fotocasa$municipality,  # Usar la columna 'municipio' para colorear los individuos
                col.var = "black",           # Las variables se mantienen en rojo
                label = "var") +           # Etiquetas de las variables activas
  labs(title = "Biplot del PCA: Separación por municipio")
```

```{r}
# Obtener nombres de columnas que terminan en '_count'
count_vars <- grep("_count$", colnames(fotocasa), value = TRUE)

# Crear nueva columna que sume todos los conteos por fila
fotocasa$entorno_score <- rowSums(fotocasa[, count_vars], na.rm = TRUE)

# Eliminar columnas originales '_count' (opcional)
fotocasa_reducido <- fotocasa[, !(colnames(fotocasa) %in% count_vars)]

variables_reducido <- fotocasa_reducido[, c(9, 10, 11, 13, 14, 15, 16,17,18,19,21,22,23,24,25,26,27,28)]

```
```{r}
K=3
res.pca_reducido = PCA(variables_reducido, scale.unit = TRUE, graph = FALSE, ncp = K, quanti.sup=16)
eig.val <- get_eigenvalue(res.pca_reducido)
VPmedio = 100 * (1/nrow(eig.val))
fviz_eig(res.pca_reducido, addlabels = TRUE) +
  geom_hline(yintercept=VPmedio, linetype=2, color="red")
kable(eig.val[1:K,])
summary(res.pca)
summary(res.pca_reducido)

```



